# -*- coding: utf-8 -*-
"""simulator.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WpBKY4_pCE4EvJlPgo1v4HKQyXm4uSDR
"""

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import losses

class Simulator:

  def __init__(self, model, nr_runs, nr_epochs, train_set, test_set, vectorize_layer):
    self.model = model
    self.nr_runs = nr_runs
    self.nr_epochs = nr_epochs
    self.train_set = train_set
    self.test_set = test_set
    self.vectorize_layer = vectorize_layer
    self.setup()

  # Prior data and model setups before running.
  def setup(self):
    # To store maximum accuracy for each run.
    self.runs_accuracy = []
    
    # Dictionary size.
    self.max_features=len(self.vectorize_layer.get_vocabulary()) + 1

    # Now specific setup parameters setup for each model.

    if self.model=="cnn":
      self.setup_shallow()
    
    if self.model == "roberta":
      self.setup_transformer()

    if self.model == "svm":
      self.setup_deterministic()

  def setup_shallow(self):
    # Word embedding dimensions.
    self.embedding_dim = 100

    #For reproducibility.
    tf.random.set_seed(1)    


  def run(self):
    if self.model == "cnn":
      self.run_cnn()

  def run_cnn(self):
    for run in range(1,(self.nr_runs+1)):
      epochs_accuracy = []
      model = tf.keras.Sequential([
                                      tf.keras.Input(shape=(1,), dtype=tf.string),
                                      self.vectorize_layer,
                                      layers.Embedding(self.max_features + 1, self.embedding_dim),                     
                                      layers.Dropout(0.8),

                                      layers.Conv1D(256,16,activation='relu'),
                                      layers.MaxPooling1D(),
                                      layers.Dropout(0.6),

                                      layers.Dense(512,activation='relu'),
                            
                                      layers.GlobalAveragePooling1D(),
                                      layers.Dropout(0.2),
                                      layers.Dense(1)                            
      ])
      model.compile(loss=losses.BinaryCrossentropy(from_logits=True), optimizer='RMSprop', metrics=tf.metrics.BinaryAccuracy(threshold=0.0)) 

      for epoch in range (0,self.nr_epochs):
          history = model.fit(
            self.train_set,
            validation_data = self.test_set,
            epochs=1,
            shuffle=False,
            # Comment the following line to do not save and download the model.
            #callbacks=[callbacks]
            )
          accuracy = history.history['val_binary_accuracy']
          print("Run: ",run,"/ Accuracy on test set at epoch ",epoch," is: ", accuracy[0],"\n")
          epochs_accuracy.append(accuracy[0])

      print("Accuracies over epochs:",epochs_accuracy,"\n")
      self.runs_accuracy.append(max(epochs_accuracy))

    self.runs_accuracy.sort()
    print("\n\n Over all runs maximum accuracies on test set are:", self.runs_accuracy)
    print("The median is:", self.runs_accuracy[2],"\n\n\n")

    # Final Result on test set
    if (self.runs_accuracy[2]-self.runs_accuracy[0])>(self.runs_accuracy[4]-self.runs_accuracy[2]):
      max_range_from_median = self.runs_accuracy[2]-self.runs_accuracy[0]
    else:
      max_range_from_median = self.runs_accuracy[4]-self.runs_accuracy[2]
    final_result = str(self.runs_accuracy[2])+" +/- "+ str(max_range_from_median)
    print("CNN Accuracy Score on test set -> ",final_result)