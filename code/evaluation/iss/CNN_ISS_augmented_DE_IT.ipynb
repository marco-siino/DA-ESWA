{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/DA-ESWA/blob/main/code/evaluation/iss/CNN_ISS_augmented_DE_IT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-hLo5ufkCT1"
      },
      "source": [
        "## Investigating text data augmentation using back translation for author profiling\n",
        "- - - \n",
        "CNN ON HSS DS EXPERIMENTS NOTEBOOK \n",
        "- - -\n",
        "Convolutional Neural Network on Irony and Stereotype Spreaders Dataset augmented with DE and IT backtranslation.\n",
        "Code by M. Siino. \n",
        "\n",
        "From the paper: \"Investigating text data augmentation using back translation for author profiling\" by M.Siino et al.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IBqUcj4cx2G"
      },
      "source": [
        "## Importing modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AQSunQ-ucjLX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "os.environ['TF_CUDNN_DETERMINISTIC']='true'\n",
        "os.environ['TF_DETERMINISTIC_OPS']='true'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QHd_fxmHCfa"
      },
      "source": [
        "## Importing DS and extract in current working directory."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urlTrainingSet = \"https://github.com/marco-siino/DA-ESWA/raw/main/data/iss/iss-training-augmented-de-it.zip\"\n",
        "training_set = tf.keras.utils.get_file(\"pan22-author-profiling-training-2022-03-29-augmented.zip\", urlTrainingSet,\n",
        "                                    extract=True, archive_format='zip',cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "urlTestSet=\"https://github.com/marco-siino/DA-ESWA/raw/main/data/iss/iss-test-original.zip\"\n",
        "test_set = tf.keras.utils.get_file(\"pan22-author-profiling-test-2022-04-22-without_truth.zip\", urlTestSet,\n",
        "                                    extract=True, archive_format='zip',cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "urlTestSetAug=\"https://github.com/marco-siino/DA-ESWA/raw/main/data/iss/iss-test-augmented-it-de.zip\"\n",
        "test_set_aug = tf.keras.utils.get_file(\"pan22-author-profiling-test-2022-04-22-without_truth-augmented.zip\", urlTestSetAug,\n",
        "                                    extract=True, archive_format='zip',cache_dir='.',\n",
        "                                    cache_subdir='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RBLe4vQPni1",
        "outputId": "d1c04fde-268e-431e-b881-218adcb0d127"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/marco-siino/DA-ESWA/raw/main/data/iss/iss-training-augmented-de-it.zip\n",
            "14016241/14016241 [==============================] - 0s 0us/step\n",
            "Downloading data from https://github.com/marco-siino/DA-ESWA/raw/main/data/iss/iss-test-original.zip\n",
            "2446477/2446477 [==============================] - 0s 0us/step\n",
            "Downloading data from https://github.com/marco-siino/DA-ESWA/raw/main/data/iss/iss-test-augmented-it-de.zip\n",
            "5815737/5815737 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ocYMUXaY8r0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3947759d-d421-49dc-d07c-53fb5c90dfad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config\n",
            "pan22-author-profiling-test-2022-04-22-without_truth\n",
            "pan22-author-profiling-test-2022-04-22-without_truth-augmented\n",
            "pan22-author-profiling-test-2022-04-22-without_truth-augmented.zip\n",
            "pan22-author-profiling-test-2022-04-22-without_truth.zip\n",
            "pan22-author-profiling-training-2022-03-29-augmented\n",
            "pan22-author-profiling-training-2022-03-29-augmented.zip\n",
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "training_set_dir = os.path.join(os.path.dirname(training_set), 'pan22-author-profiling-training-2022-03-29-augmented')\n",
        "test_set_dir = os.path.join(os.path.dirname(test_set), 'pan22-author-profiling-test-2022-04-22-without_truth')\n",
        "test_set_aug_dir = os.path.join(os.path.dirname(test_set_aug), 'pan22-author-profiling-test-2022-04-22-without_truth-augmented')\n",
        "\n",
        "!ls -A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTJi1fbT_Rup"
      },
      "source": [
        "## Build folders hierarchy to use Keras folders preprocessing function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FyafvXEMhEKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a33cdab-fb6d-4b26-ff85-a77678578fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config\n",
            "pan22-author-profiling-test-2022-04-22-without_truth\n",
            "pan22-author-profiling-test-2022-04-22-without_truth-augmented\n",
            "pan22-author-profiling-test-2022-04-22-without_truth-augmented.zip\n",
            "pan22-author-profiling-test-2022-04-22-without_truth.zip\n",
            "pan22-author-profiling-training-2022-03-29-augmented\n",
            "pan22-author-profiling-training-2022-03-29-augmented.zip\n",
            "sample_data\n",
            "test_aug_dir_en\n",
            "test_dir_en\n",
            "train_dir_en\n"
          ]
        }
      ],
      "source": [
        "### Training Folders. ###\n",
        "\n",
        "# First level directory.\n",
        "if not os.path.exists('train_dir_en'):\n",
        "    os.makedirs('train_dir_en')\n",
        "\n",
        "# Class labels directory.\n",
        "if not os.path.exists('train_dir_en/0'):\n",
        "    os.makedirs('train_dir_en/0')\n",
        "if not os.path.exists('train_dir_en/1'):\n",
        "    os.makedirs('train_dir_en/1')\n",
        "\n",
        "# Make Py variables.\n",
        "train_dir='train_dir_'\n",
        "\n",
        "## Test Folders. ##\n",
        "# First level directory.\n",
        "if not os.path.exists('test_dir_en'):\n",
        "    os.makedirs('test_dir_en')\n",
        "\n",
        "# Class labels directory.\n",
        "if not os.path.exists('test_dir_en/0'):\n",
        "    os.makedirs('test_dir_en/0')\n",
        "if not os.path.exists('test_dir_en/1'):\n",
        "    os.makedirs('test_dir_en/1')\n",
        "\n",
        "# Make Py variables.\n",
        "test_dir='test_dir_'\n",
        "\n",
        "## Test Augmented Folders. ##\n",
        "# First level directory.\n",
        "if not os.path.exists('test_aug_dir_en'):\n",
        "    os.makedirs('test_aug_dir_en')\n",
        "\n",
        "# Class labels directory.\n",
        "if not os.path.exists('test_aug_dir_en/0'):\n",
        "    os.makedirs('test_aug_dir_en/0')\n",
        "if not os.path.exists('test_aug_dir_en/1'):\n",
        "    os.makedirs('test_aug_dir_en/1')\n",
        "\n",
        "# Make Py variables.\n",
        "test_aug_dir='test_aug_dir_'\n",
        "\n",
        "!ls -A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set language and directory paths."
      ],
      "metadata": {
        "id": "-6c28Rdo8zGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set en and es ground truth file path for train_dir. \n",
        "language='en'\n",
        "\n",
        "truth_file_training_dir_en=training_set_dir+'/'+language+'/'\n",
        "truth_file_training_path_en = truth_file_training_dir_en+'truth.txt'\n",
        "\n",
        "truth_file_test_dir=test_set_dir\n",
        "truth_file_test_path_en = truth_file_test_dir+'/'+'truth'+'.txt'\n",
        "\n",
        "truth_file_test_aug_dir=test_set_aug_dir\n",
        "truth_file_test_aug_path_en = truth_file_test_aug_dir+'/'+'truth'+'.txt'"
      ],
      "metadata": {
        "id": "ANr_dCj-8yvD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read truth.txt to organize training and test dataset folders."
      ],
      "metadata": {
        "id": "VU6PtNMZ864o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file truth.txt with read only permit.\n",
        "f = open(truth_file_training_path_en, \"r\")\n",
        "# use readline() to read the first line \n",
        "line = f.readline()\n",
        "# use the read line to read further.\n",
        "# If the file is not empty keep reading one line\n",
        "# at a time, till the file is empty\n",
        "while line:\n",
        "    # Split line at :::\n",
        "    x = line.split(\":::\")\n",
        "    fNameXml = x[0]+'.xml'\n",
        "    fNameTxt = x[0]+'.txt'\n",
        "    # Second coord [0] gets just the first character (label) and not /n too.\n",
        "    label = x[1][0]\n",
        "    if label == 'I':\n",
        "      label = '1'\n",
        "    elif label == 'N':\n",
        "      label = '0'\n",
        "\n",
        "    # Now move the file to the right folder.\n",
        "    if os.path.exists(truth_file_training_dir_en+fNameXml):\n",
        "      os.rename(truth_file_training_dir_en+fNameXml, './train_dir_'+language+'/'+label+'/'+fNameTxt )\n",
        "\n",
        "    # use readline() to read next line\n",
        "    line = f.readline()\n",
        "\n",
        "# Open the file truth.txt with read only permit.\n",
        "f = open(truth_file_test_path_en, \"r\")\n",
        "# use readline() to read the first line \n",
        "line = f.readline()\n",
        "# use the read line to read further.\n",
        "# If the file is not empty keep reading one line\n",
        "# at a time, till the file is empty\n",
        "while line:\n",
        "    # Split line at :::\n",
        "    x = line.split(\":::\")\n",
        "    fNameXml = x[0]+'.xml'\n",
        "    fNameTxt = x[0]+'.txt'\n",
        "    # Second coord [0] gets just the first character (label) and not /n too.\n",
        "    label = x[1][0]\n",
        "    if label == 'I':\n",
        "      label = '1'\n",
        "    elif label == 'N':\n",
        "      label = '0'\n",
        "\n",
        "    # Now move the file to the right folder.\n",
        "    if os.path.exists(truth_file_test_dir+'/'+language+'/'+fNameXml):\n",
        "      os.rename(truth_file_test_dir+'/'+language+'/'+fNameXml, './test_dir_'+language+'/'+label+'/'+fNameTxt )\n",
        "\n",
        "    # use readline() to read next line\n",
        "    line = f.readline()\n",
        "\n",
        "# Open the file truth.txt with read only permit.\n",
        "f = open(truth_file_test_aug_path_en, \"r\")\n",
        "# use readline() to read the first line \n",
        "line = f.readline()\n",
        "# use the read line to read further.\n",
        "# If the file is not empty keep reading one line\n",
        "# at a time, till the file is empty\n",
        "while line:\n",
        "    # Split line at :::\n",
        "    x = line.split(\":::\")\n",
        "    fNameXml = x[0]+'.xml'\n",
        "    fNameTxt = x[0]+'.txt'\n",
        "    # Second coord [0] gets just the first character (label) and not /n too.\n",
        "    label = x[1][0]\n",
        "    if label == 'I':\n",
        "      label = '1'\n",
        "    elif label == 'N':\n",
        "      label = '0'\n",
        "\n",
        "    # Now move the file to the right folder.\n",
        "    if os.path.exists(truth_file_test_aug_dir+'/'+language+'/'+fNameXml):\n",
        "      os.rename(truth_file_test_aug_dir+'/'+language+'/'+fNameXml, './test_aug_dir_'+language+'/'+label+'/'+fNameTxt )\n",
        "\n",
        "    # use readline() to read next line\n",
        "    line = f.readline()"
      ],
      "metadata": {
        "id": "iW2UF_SH87TX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate full dataset."
      ],
      "metadata": {
        "id": "4vskGJeX9GqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate full randomized training set.\n",
        "batch_size=1\n",
        "\n",
        "en_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    train_dir+language, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        "    )\n",
        "\n",
        "en_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    test_dir+language, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        "    )\n",
        "\n",
        "en_test_aug_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    test_aug_dir+language, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        "    )\n",
        "\n",
        "train_ds=en_train_ds.shuffle(500,seed=1, reshuffle_each_iteration=False)\n",
        "test_ds=en_test_ds.shuffle(200,seed=1, reshuffle_each_iteration=False)\n",
        "test_aug_ds=en_test_aug_ds.shuffle(200,seed=1, reshuffle_each_iteration=False)\n",
        "\n",
        "train_ds_size=len(train_ds)\n",
        "test_ds_size=len(test_ds)\n",
        "test_aug_ds_size=len(test_aug_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOqIc_Sm9HGX",
        "outputId": "0685746f-d9ff-4557-dbbc-d34c43093ed7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 420 files belonging to 2 classes.\n",
            "Found 180 files belonging to 2 classes.\n",
            "Found 180 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITouXXtQ8WzV"
      },
      "source": [
        "## Functions to pre-process source text. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bDPIqAgXYWim"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function to remove some noise due to the translation.\n",
        "def clean_samples(input_data):\n",
        "  tag_author_lang_en_removed = tf.strings.regex_replace(input_data,'', '')  \n",
        "  tag_opening_documents = tf.strings.regex_replace(tag_author_lang_en_removed,'', '')\n",
        "  tag_opening_cdata_removed = tf.strings.regex_replace(tag_opening_documents,'<\\!\\[CDATA\\[', ' ')\n",
        "  tag_closing_cdata_removed = tf.strings.regex_replace(tag_opening_cdata_removed,'\\]\\]>', ' >')\n",
        "  tag_closing_documents = tf.strings.regex_replace(tag_closing_cdata_removed,'', '')\n",
        "  output_data = tf.strings.regex_replace(tag_closing_documents,'', '')\n",
        "  tag_author_lang_en_removed = tf.strings.regex_replace(output_data,'<author lang=\"en\"', '')\n",
        "  tag_author_lang_en_cased_removed = tf.strings.regex_replace(tag_author_lang_en_removed,'<Author lang=\"en\"', '\\n\\n')\n",
        "  tag_opening_document_miscased = tf.strings.regex_replace(tag_author_lang_en_cased_removed,'<Document>', '<document>')\n",
        "  output_data = tf.strings.regex_replace(tag_opening_document_miscased,'</Document>', '</document>')\n",
        "  return output_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjUnE9_DEyCw"
      },
      "source": [
        "## Get the length of the longest sample in training set. Then adapt text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ebRMQqa_mr48"
      },
      "outputs": [],
      "source": [
        "def preprocess_and_adapt_ts(training_set):\n",
        "  # Set a large sequence length to find the longest sample in the training set.\n",
        "  sequence_length = 30000\n",
        "  vectorize_layer = TextVectorization(\n",
        "      standardize=clean_samples,\n",
        "      output_mode='int',\n",
        "      output_sequence_length=sequence_length)\n",
        "\n",
        "  train_text = training_set.map(lambda x, y: x)\n",
        "  vectorize_layer.adapt(train_text)\n",
        "  #vectorize_layer.get_vocabulary()\n",
        "\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "  model.add(vectorize_layer)\n",
        "\n",
        "  longest_sample_length=1\n",
        "\n",
        "  for element in training_set:\n",
        "    authorDocument=element[0]\n",
        "    label=element[1]\n",
        "    \n",
        "    #print(\"Sample considered is: \", authorDocument[0].numpy())\n",
        "    #print(\"Preprocessed: \", str(custom_standardization(authorDocument[0].numpy())))\n",
        "    #print(\"And has label: \", label[0].numpy())\n",
        "\n",
        "    out=model(authorDocument)\n",
        "    # Convert token list to numpy array.\n",
        "    token_list = out.numpy()[0]\n",
        "    token_list = np.trim_zeros(token_list,'b')\n",
        "    if longest_sample_length < len(token_list):\n",
        "      longest_sample_length = len(token_list)\n",
        "\n",
        "  print(\"Length of the longest sample is:\", longest_sample_length)\n",
        "\n",
        "  # After tokenization longest_sample_length covers all the document lenghts in our dataset.\n",
        "  sequence_length = longest_sample_length\n",
        "\n",
        "  vectorize_layer = TextVectorization(\n",
        "      standardize=clean_samples,\n",
        "      output_mode='int',\n",
        "      output_sequence_length=sequence_length)\n",
        "\n",
        "  # Finally adapt the vectorize layer.\n",
        "  train_text = training_set.map(lambda x, y: x)\n",
        "  vectorize_layer.adapt(train_text)\n",
        "  return vectorize_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some training hyperparameters..."
      ],
      "metadata": {
        "id": "RF7pJkGJ3bHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word embedding dimensions.\n",
        "embedding_dim = 100\n",
        "\n",
        "num_runs = 5 \n",
        "# No need to go over the 20th epoch...Overfitting begins.\n",
        "num_epochs_per_run = 20\n",
        "\n",
        "#opt = tf.keras.optimizers.RMSprop()"
      ],
      "metadata": {
        "id": "ocHligxS3mVn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yzLLcBGdtmXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n* * * * VECTORIZATION STARTED * * * *\")\n",
        "\n",
        "# Preprocess training set to build a dictionary.\n",
        "vectorize_layer = preprocess_and_adapt_ts(train_ds)\n",
        "\n",
        "max_features=len(vectorize_layer.get_vocabulary()) + 1\n",
        "print(\"Vocabulary size is:\", max_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlDEHJvstluS",
        "outputId": "dd2a9255-b116-4c09-c835-6fb23de122a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "* * * * VECTORIZATION STARTED * * * *\n",
            "Length of the longest sample is: 29411\n",
            "Vocabulary size is: 258982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDEi7MAo4qsQ"
      },
      "source": [
        "## Models definition, training and evaluation on original and on augmented test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm1fdCpETWL-",
        "outputId": "1ff88b04-dadb-4ced-b2c9-f78b48c483fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420/420 [==============================] - 190s 428ms/step - loss: 0.6745 - binary_accuracy: 0.5667 - val_loss: 0.9960 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  0  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  0  is:  0.7611111402511597 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 0.3929 - binary_accuracy: 0.8357 - val_loss: 2.1316 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  1  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  1  is:  0.9111111164093018 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 0.2553 - binary_accuracy: 0.9071 - val_loss: 2.2149 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  2  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  2  is:  0.9277777671813965 \n",
            "\n",
            "420/420 [==============================] - 115s 273ms/step - loss: 0.1755 - binary_accuracy: 0.9429 - val_loss: 2.9135 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  3  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  3  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 123s 292ms/step - loss: 0.1152 - binary_accuracy: 0.9595 - val_loss: 3.3706 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  4  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  4  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0739 - binary_accuracy: 0.9810 - val_loss: 4.5032 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  5  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  5  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 0.0546 - binary_accuracy: 0.9881 - val_loss: 5.1976 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  6  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  6  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0382 - binary_accuracy: 0.9929 - val_loss: 5.5737 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  7  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  7  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 115s 275ms/step - loss: 0.0384 - binary_accuracy: 0.9952 - val_loss: 6.4575 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  8  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  8  is:  0.949999988079071 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0083 - binary_accuracy: 0.9952 - val_loss: 6.1989 - val_binary_accuracy: 0.5056\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  9  is:  0.5055555701255798 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  9  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 8.4343 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  10  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  10  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 2.4670e-04 - binary_accuracy: 1.0000 - val_loss: 9.4009 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  11  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  11  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 9.3628e-05 - binary_accuracy: 1.0000 - val_loss: 10.4677 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  12  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  12  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 4.3685e-04 - binary_accuracy: 1.0000 - val_loss: 9.2203 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  13  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  13  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 2.6943e-04 - binary_accuracy: 1.0000 - val_loss: 9.9605 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  14  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  14  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 4.1928e-05 - binary_accuracy: 1.0000 - val_loss: 12.9748 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  15  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  15  is:  0.9166666865348816 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 6.6020e-05 - binary_accuracy: 1.0000 - val_loss: 12.8628 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  16  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  16  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 2.5515e-05 - binary_accuracy: 1.0000 - val_loss: 13.7193 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  17  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  17  is:  0.9166666865348816 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 3.0041e-05 - binary_accuracy: 1.0000 - val_loss: 14.4230 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  18  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  18  is:  0.9111111164093018 \n",
            "\n",
            "420/420 [==============================] - 123s 293ms/step - loss: 1.9134e-05 - binary_accuracy: 1.0000 - val_loss: 14.9943 - val_binary_accuracy: 0.5000\n",
            "Run:  1 / Accuracy on test ORIGINAL at epoch  19  is:  0.5 \n",
            "\n",
            "Run:  1 / Accuracy on test AUGMENTED at epoch  19  is:  0.9111111164093018 \n",
            "\n",
            "Accuracies on ORIGINAL over epochs: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5055555701255798, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] \n",
            "\n",
            "Accuracies on AUGMENTED over epochs: [0.7611111402511597, 0.9111111164093018, 0.9277777671813965, 0.9333333373069763, 0.9388889074325562, 0.9388889074325562, 0.9333333373069763, 0.9388889074325562, 0.949999988079071, 0.9333333373069763, 0.9444444179534912, 0.9444444179534912, 0.9444444179534912, 0.9388889074325562, 0.9388889074325562, 0.9166666865348816, 0.9333333373069763, 0.9166666865348816, 0.9111111164093018, 0.9111111164093018] \n",
            "\n",
            "\n",
            "420/420 [==============================] - 166s 392ms/step - loss: 0.6800 - binary_accuracy: 0.5500 - val_loss: 0.8035 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  0  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  0  is:  0.7444444298744202 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.3938 - binary_accuracy: 0.8452 - val_loss: 2.1526 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  1  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  1  is:  0.9111111164093018 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.2457 - binary_accuracy: 0.9071 - val_loss: 2.5745 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  2  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  2  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 0.1739 - binary_accuracy: 0.9500 - val_loss: 3.1392 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  3  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  3  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 0.1107 - binary_accuracy: 0.9595 - val_loss: 4.0008 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  4  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  4  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 0.0803 - binary_accuracy: 0.9786 - val_loss: 4.5963 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  5  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  5  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 0.0521 - binary_accuracy: 0.9905 - val_loss: 5.4721 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  6  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  6  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.0375 - binary_accuracy: 0.9929 - val_loss: 5.6264 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  7  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  7  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0318 - binary_accuracy: 0.9952 - val_loss: 5.5845 - val_binary_accuracy: 0.5111\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  8  is:  0.5111111402511597 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  8  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.0232 - binary_accuracy: 0.9929 - val_loss: 6.3432 - val_binary_accuracy: 0.5056\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  9  is:  0.5055555701255798 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  9  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 0.0075 - binary_accuracy: 0.9976 - val_loss: 7.4719 - val_binary_accuracy: 0.5056\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  10  is:  0.5055555701255798 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  10  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 6.3951e-04 - binary_accuracy: 1.0000 - val_loss: 8.4747 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  11  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  11  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 6.2800e-04 - binary_accuracy: 1.0000 - val_loss: 9.1599 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  12  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  12  is:  0.9555555582046509 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 6.2321e-05 - binary_accuracy: 1.0000 - val_loss: 10.7255 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  13  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  13  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 1.8526e-05 - binary_accuracy: 1.0000 - val_loss: 10.4796 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  14  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  14  is:  0.949999988079071 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 5.6415e-05 - binary_accuracy: 1.0000 - val_loss: 11.3442 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  15  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  15  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 2.8523e-05 - binary_accuracy: 1.0000 - val_loss: 12.8767 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  16  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  16  is:  0.9166666865348816 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 4.7978e-05 - binary_accuracy: 1.0000 - val_loss: 11.4281 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  17  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  17  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 6.7362e-06 - binary_accuracy: 1.0000 - val_loss: 13.1487 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  18  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  18  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 1.5157e-05 - binary_accuracy: 1.0000 - val_loss: 13.4496 - val_binary_accuracy: 0.5000\n",
            "Run:  2 / Accuracy on test ORIGINAL at epoch  19  is:  0.5 \n",
            "\n",
            "Run:  2 / Accuracy on test AUGMENTED at epoch  19  is:  0.9277777671813965 \n",
            "\n",
            "Accuracies on ORIGINAL over epochs: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5111111402511597, 0.5055555701255798, 0.5055555701255798, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] \n",
            "\n",
            "Accuracies on AUGMENTED over epochs: [0.7444444298744202, 0.9111111164093018, 0.9333333373069763, 0.9222221970558167, 0.9222221970558167, 0.9333333373069763, 0.9333333373069763, 0.9388889074325562, 0.9333333373069763, 0.9333333373069763, 0.9444444179534912, 0.9444444179534912, 0.9555555582046509, 0.9388889074325562, 0.949999988079071, 0.9388889074325562, 0.9166666865348816, 0.9444444179534912, 0.9333333373069763, 0.9277777671813965] \n",
            "\n",
            "\n",
            "420/420 [==============================] - 156s 369ms/step - loss: 0.6743 - binary_accuracy: 0.5500 - val_loss: 0.9922 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  0  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  0  is:  0.7222222089767456 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.3939 - binary_accuracy: 0.8405 - val_loss: 2.1343 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  1  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  1  is:  0.9055555462837219 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.2572 - binary_accuracy: 0.9119 - val_loss: 2.5465 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  2  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  2  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 0.1810 - binary_accuracy: 0.9405 - val_loss: 2.8925 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  3  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  3  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 0.1132 - binary_accuracy: 0.9690 - val_loss: 3.3241 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  4  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  4  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0819 - binary_accuracy: 0.9786 - val_loss: 4.0993 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  5  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  5  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 124s 295ms/step - loss: 0.0482 - binary_accuracy: 0.9857 - val_loss: 4.8619 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  6  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  6  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 0.0390 - binary_accuracy: 0.9905 - val_loss: 5.8518 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  7  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  7  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.0283 - binary_accuracy: 0.9952 - val_loss: 6.1563 - val_binary_accuracy: 0.5056\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  8  is:  0.5055555701255798 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  8  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0074 - binary_accuracy: 0.9976 - val_loss: 5.9451 - val_binary_accuracy: 0.5111\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  9  is:  0.5111111402511597 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  9  is:  0.9277777671813965 \n",
            "\n",
            "420/420 [==============================] - 112s 268ms/step - loss: 0.0041 - binary_accuracy: 0.9976 - val_loss: 8.7079 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  10  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  10  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 10.5019 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  11  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  11  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 1.6495e-04 - binary_accuracy: 1.0000 - val_loss: 9.2707 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  12  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  12  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.0024 - binary_accuracy: 0.9976 - val_loss: 11.8244 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  13  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  13  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 7.7783e-05 - binary_accuracy: 1.0000 - val_loss: 11.7476 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  14  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  14  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 112s 266ms/step - loss: 5.7910e-05 - binary_accuracy: 1.0000 - val_loss: 11.6624 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  15  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  15  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 3.2246e-05 - binary_accuracy: 1.0000 - val_loss: 11.9567 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  16  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  16  is:  0.949999988079071 \n",
            "\n",
            "420/420 [==============================] - 112s 268ms/step - loss: 5.7204e-06 - binary_accuracy: 1.0000 - val_loss: 13.2346 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  17  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  17  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 1.0987e-05 - binary_accuracy: 1.0000 - val_loss: 14.0590 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  18  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  18  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 6.9693e-05 - binary_accuracy: 1.0000 - val_loss: 12.9164 - val_binary_accuracy: 0.5000\n",
            "Run:  3 / Accuracy on test ORIGINAL at epoch  19  is:  0.5 \n",
            "\n",
            "Run:  3 / Accuracy on test AUGMENTED at epoch  19  is:  0.9444444179534912 \n",
            "\n",
            "Accuracies on ORIGINAL over epochs: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5055555701255798, 0.5111111402511597, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] \n",
            "\n",
            "Accuracies on AUGMENTED over epochs: [0.7222222089767456, 0.9055555462837219, 0.9333333373069763, 0.9333333373069763, 0.9333333373069763, 0.9388889074325562, 0.9444444179534912, 0.9388889074325562, 0.9333333373069763, 0.9277777671813965, 0.9333333373069763, 0.9333333373069763, 0.9388889074325562, 0.9222221970558167, 0.9388889074325562, 0.9388889074325562, 0.949999988079071, 0.9388889074325562, 0.9333333373069763, 0.9444444179534912] \n",
            "\n",
            "\n",
            "420/420 [==============================] - 154s 363ms/step - loss: 0.6805 - binary_accuracy: 0.5405 - val_loss: 0.7929 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  0  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  0  is:  0.7333333492279053 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.3933 - binary_accuracy: 0.8452 - val_loss: 2.1408 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  1  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  1  is:  0.9166666865348816 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 0.2471 - binary_accuracy: 0.9071 - val_loss: 2.4671 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  2  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  2  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 0.1685 - binary_accuracy: 0.9452 - val_loss: 3.1609 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  3  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  3  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.1102 - binary_accuracy: 0.9667 - val_loss: 4.0157 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  4  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  4  is:  0.9277777671813965 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 0.0722 - binary_accuracy: 0.9810 - val_loss: 4.8399 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  5  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  5  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.0546 - binary_accuracy: 0.9857 - val_loss: 5.6613 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  6  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  6  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 0.0382 - binary_accuracy: 0.9929 - val_loss: 6.1545 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  7  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  7  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0260 - binary_accuracy: 0.9952 - val_loss: 7.1537 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  8  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  8  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 0.0148 - binary_accuracy: 0.9952 - val_loss: 7.6002 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  9  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  9  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0045 - binary_accuracy: 0.9976 - val_loss: 8.7382 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  10  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  10  is:  0.9555555582046509 \n",
            "\n",
            "420/420 [==============================] - 113s 270ms/step - loss: 5.1476e-04 - binary_accuracy: 1.0000 - val_loss: 9.3042 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  11  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  11  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 114s 273ms/step - loss: 3.7651e-04 - binary_accuracy: 1.0000 - val_loss: 9.8533 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  12  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  12  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 6.4463e-05 - binary_accuracy: 1.0000 - val_loss: 12.9459 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  13  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  13  is:  0.9111111164093018 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 9.2768e-05 - binary_accuracy: 1.0000 - val_loss: 13.5089 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  14  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  14  is:  0.9111111164093018 \n",
            "\n",
            "420/420 [==============================] - 123s 294ms/step - loss: 7.8658e-06 - binary_accuracy: 1.0000 - val_loss: 14.4617 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  15  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  15  is:  0.8777777552604675 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 1.1574e-04 - binary_accuracy: 1.0000 - val_loss: 14.8497 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  16  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  16  is:  0.9111111164093018 \n",
            "\n",
            "420/420 [==============================] - 112s 268ms/step - loss: 4.5399e-04 - binary_accuracy: 1.0000 - val_loss: 13.8488 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  17  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  17  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 114s 272ms/step - loss: 4.7238e-04 - binary_accuracy: 1.0000 - val_loss: 14.6514 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  18  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  18  is:  0.9055555462837219 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 6.4530e-06 - binary_accuracy: 1.0000 - val_loss: 15.1187 - val_binary_accuracy: 0.5000\n",
            "Run:  4 / Accuracy on test ORIGINAL at epoch  19  is:  0.5 \n",
            "\n",
            "Run:  4 / Accuracy on test AUGMENTED at epoch  19  is:  0.894444465637207 \n",
            "\n",
            "Accuracies on ORIGINAL over epochs: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5] \n",
            "\n",
            "Accuracies on AUGMENTED over epochs: [0.7333333492279053, 0.9166666865348816, 0.9333333373069763, 0.9222221970558167, 0.9277777671813965, 0.9333333373069763, 0.9388889074325562, 0.9444444179534912, 0.9444444179534912, 0.9388889074325562, 0.9555555582046509, 0.9388889074325562, 0.9444444179534912, 0.9111111164093018, 0.9111111164093018, 0.8777777552604675, 0.9111111164093018, 0.9222221970558167, 0.9055555462837219, 0.894444465637207] \n",
            "\n",
            "\n",
            "420/420 [==============================] - 156s 370ms/step - loss: 0.6863 - binary_accuracy: 0.5310 - val_loss: 0.6988 - val_binary_accuracy: 0.5000\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  0  is:  0.5 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  0  is:  0.6388888955116272 \n",
            "\n",
            "420/420 [==============================] - 114s 271ms/step - loss: 0.4288 - binary_accuracy: 0.8452 - val_loss: 0.9246 - val_binary_accuracy: 0.5000\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  1  is:  0.5 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  1  is:  0.9111111164093018 \n",
            "\n",
            "420/420 [==============================] - 111s 263ms/step - loss: 0.2257 - binary_accuracy: 0.9119 - val_loss: 1.2486 - val_binary_accuracy: 0.5000\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  2  is:  0.5 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  2  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 0.1462 - binary_accuracy: 0.9524 - val_loss: 1.6084 - val_binary_accuracy: 0.5056\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  3  is:  0.5055555701255798 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  3  is:  0.9166666865348816 \n",
            "\n",
            "420/420 [==============================] - 112s 266ms/step - loss: 0.0928 - binary_accuracy: 0.9667 - val_loss: 1.8370 - val_binary_accuracy: 0.5056\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  4  is:  0.5055555701255798 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  4  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 0.0552 - binary_accuracy: 0.9738 - val_loss: 2.1181 - val_binary_accuracy: 0.5167\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  5  is:  0.5166666507720947 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  5  is:  0.9333333373069763 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 0.0302 - binary_accuracy: 0.9929 - val_loss: 2.2847 - val_binary_accuracy: 0.5222\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  6  is:  0.5222222208976746 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  6  is:  0.949999988079071 \n",
            "\n",
            "420/420 [==============================] - 112s 266ms/step - loss: 0.0240 - binary_accuracy: 0.9929 - val_loss: 2.7800 - val_binary_accuracy: 0.5167\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  7  is:  0.5166666507720947 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  7  is:  0.9388889074325562 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 0.0135 - binary_accuracy: 0.9952 - val_loss: 3.2025 - val_binary_accuracy: 0.5167\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  8  is:  0.5166666507720947 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  8  is:  0.9055555462837219 \n",
            "\n",
            "420/420 [==============================] - 111s 264ms/step - loss: 0.0039 - binary_accuracy: 0.9976 - val_loss: 3.5229 - val_binary_accuracy: 0.5167\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  9  is:  0.5166666507720947 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  9  is:  0.9222221970558167 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 4.8458e-04 - binary_accuracy: 1.0000 - val_loss: 3.9883 - val_binary_accuracy: 0.5167\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  10  is:  0.5166666507720947 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  10  is:  0.8999999761581421 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 8.9057e-05 - binary_accuracy: 1.0000 - val_loss: 4.2569 - val_binary_accuracy: 0.5111\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  11  is:  0.5111111402511597 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  11  is:  0.894444465637207 \n",
            "\n",
            "420/420 [==============================] - 123s 293ms/step - loss: 4.8504e-05 - binary_accuracy: 1.0000 - val_loss: 4.2819 - val_binary_accuracy: 0.5111\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  12  is:  0.5111111402511597 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  12  is:  0.8999999761581421 \n",
            "\n",
            "420/420 [==============================] - 121s 288ms/step - loss: 5.6953e-05 - binary_accuracy: 1.0000 - val_loss: 4.7163 - val_binary_accuracy: 0.5111\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  13  is:  0.5111111402511597 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  13  is:  0.8777777552604675 \n",
            "\n",
            "420/420 [==============================] - 112s 266ms/step - loss: 5.1284e-05 - binary_accuracy: 1.0000 - val_loss: 4.5742 - val_binary_accuracy: 0.5111\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  14  is:  0.5111111402511597 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  14  is:  0.8999999761581421 \n",
            "\n",
            "420/420 [==============================] - 113s 269ms/step - loss: 5.5070e-05 - binary_accuracy: 1.0000 - val_loss: 4.2494 - val_binary_accuracy: 0.5167\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  15  is:  0.5166666507720947 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  15  is:  0.9444444179534912 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 3.0812e-05 - binary_accuracy: 1.0000 - val_loss: 5.2415 - val_binary_accuracy: 0.5056\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  16  is:  0.5055555701255798 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  16  is:  0.8611111044883728 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 2.2225e-05 - binary_accuracy: 1.0000 - val_loss: 5.0241 - val_binary_accuracy: 0.5111\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  17  is:  0.5111111402511597 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  17  is:  0.894444465637207 \n",
            "\n",
            "420/420 [==============================] - 112s 267ms/step - loss: 5.6879e-05 - binary_accuracy: 1.0000 - val_loss: 5.0626 - val_binary_accuracy: 0.5111\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  18  is:  0.5111111402511597 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  18  is:  0.8999999761581421 \n",
            "\n",
            "420/420 [==============================] - 113s 268ms/step - loss: 3.5787e-05 - binary_accuracy: 1.0000 - val_loss: 5.2097 - val_binary_accuracy: 0.5111\n",
            "Run:  5 / Accuracy on test ORIGINAL at epoch  19  is:  0.5111111402511597 \n",
            "\n",
            "Run:  5 / Accuracy on test AUGMENTED at epoch  19  is:  0.8833333253860474 \n",
            "\n",
            "Accuracies on ORIGINAL over epochs: [0.5, 0.5, 0.5, 0.5055555701255798, 0.5055555701255798, 0.5166666507720947, 0.5222222208976746, 0.5166666507720947, 0.5166666507720947, 0.5166666507720947, 0.5166666507720947, 0.5111111402511597, 0.5111111402511597, 0.5111111402511597, 0.5111111402511597, 0.5166666507720947, 0.5055555701255798, 0.5111111402511597, 0.5111111402511597, 0.5111111402511597] \n",
            "\n",
            "Accuracies on AUGMENTED over epochs: [0.6388888955116272, 0.9111111164093018, 0.9222221970558167, 0.9166666865348816, 0.9222221970558167, 0.9333333373069763, 0.949999988079071, 0.9388889074325562, 0.9055555462837219, 0.9222221970558167, 0.8999999761581421, 0.894444465637207, 0.8999999761581421, 0.8777777552604675, 0.8999999761581421, 0.9444444179534912, 0.8611111044883728, 0.894444465637207, 0.8999999761581421, 0.8833333253860474] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Over all runs maximum accuracies on ORIGINAL test set are: [0.5, 0.5055555701255798, 0.5111111402511597, 0.5111111402511597, 0.5222222208976746]\n",
            "The median for English is: 0.5111111402511597 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Over all runs maximum accuracies on AUGMENTED test set are: [0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9555555582046509, 0.9555555582046509]\n",
            "The median for English is: 0.949999988079071 \n",
            "\n",
            "\n",
            "\n",
            "CNN Accuracy Score on Original Test set ->  0.5111111402511597 +/- 0.011111140251159668\n",
            "CNN Accuracy Score on AUGMENTED Test set ->  0.949999988079071 +/- 0.005555570125579834\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(1)\n",
        "\n",
        "runs_accuracy = []\n",
        "aug_runs_accuracy = []\n",
        "\n",
        "for run in range(1,(num_runs+1)):\n",
        "    epochs_accuracy = []\n",
        "    aug_epochs_accuracy = []\n",
        "    model = tf.keras.Sequential([\n",
        "                                    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
        "                                    vectorize_layer,\n",
        "                                    layers.Embedding(max_features + 1, embedding_dim),                     \n",
        "                                    layers.Dropout(0.8),\n",
        "\n",
        "                                    layers.Conv1D(256,16,activation='relu'),\n",
        "                                    layers.MaxPooling1D(),\n",
        "                                    layers.Dropout(0.6),\n",
        "\n",
        "                                    layers.Dense(512,activation='relu'),\n",
        "                           \n",
        "                                    layers.GlobalAveragePooling1D(),\n",
        "                                    layers.Dropout(0.2),\n",
        "                                    layers.Dense(1)                            \n",
        "    ])\n",
        "    model.compile(loss=losses.BinaryCrossentropy(from_logits=True), optimizer='RMSprop', metrics=tf.metrics.BinaryAccuracy(threshold=0.0)) \n",
        "\n",
        "    for epoch in range (0,num_epochs_per_run):\n",
        "        history = model.fit(\n",
        "          train_ds,\n",
        "          validation_data = test_ds,\n",
        "          epochs=1,\n",
        "          shuffle=False,\n",
        "          # Comment the following line to do not save and download the model.\n",
        "          #callbacks=[callbacks]\n",
        "          )\n",
        "        accuracy = history.history['val_binary_accuracy']\n",
        "        aug_score = model.evaluate(test_aug_ds, verbose=0)\n",
        "        aug_accuracy = aug_score[1]\n",
        "        print(\"Run: \",run,\"/ Accuracy on test ORIGINAL at epoch \",epoch,\" is: \", accuracy[0],\"\\n\")\n",
        "        print(\"Run: \",run,\"/ Accuracy on test AUGMENTED at epoch \",epoch,\" is: \", aug_accuracy,\"\\n\")\n",
        "        epochs_accuracy.append(accuracy[0])\n",
        "        aug_epochs_accuracy.append(aug_accuracy)\n",
        "\n",
        "    print(\"Accuracies on ORIGINAL over epochs:\",epochs_accuracy,\"\\n\")\n",
        "    runs_accuracy.append(max(epochs_accuracy))\n",
        "    print(\"Accuracies on AUGMENTED over epochs:\",aug_epochs_accuracy,\"\\n\\n\")\n",
        "    aug_runs_accuracy.append(max(aug_epochs_accuracy))\n",
        "\n",
        "runs_accuracy.sort()\n",
        "aug_runs_accuracy.sort()\n",
        "print(\"\\n\\n Over all runs maximum accuracies on ORIGINAL test set are:\", runs_accuracy)\n",
        "print(\"The median for English is:\",runs_accuracy[2],\"\\n\\n\\n\")\n",
        "  \n",
        "print(\"\\n\\n Over all runs maximum accuracies on AUGMENTED test set are:\", aug_runs_accuracy)\n",
        "print(\"The median for English is:\",aug_runs_accuracy[2],\"\\n\\n\\n\")\n",
        "\n",
        "# Final Result on Original Test set\n",
        "if (runs_accuracy[2]-runs_accuracy[0])>(runs_accuracy[4]-runs_accuracy[2]):\n",
        "  max_range_from_median = runs_accuracy[2]-runs_accuracy[0]\n",
        "else:\n",
        "  max_range_from_median = runs_accuracy[4]-runs_accuracy[2]\n",
        "final_result = str(runs_accuracy[2])+\" +/- \"+ str(max_range_from_median)\n",
        "print(\"CNN Accuracy Score on Original Test set -> \",final_result)\n",
        "\n",
        "# Final result on AUGMENTED test set.\n",
        "if (aug_runs_accuracy[2]-aug_runs_accuracy[0])>(aug_runs_accuracy[4]-aug_runs_accuracy[2]):\n",
        "  max_range_from_median = aug_runs_accuracy[2]-aug_runs_accuracy[0]\n",
        "else:\n",
        "  max_range_from_median = aug_runs_accuracy[4]-aug_runs_accuracy[2]\n",
        "final_result = str(aug_runs_accuracy[2])+\" +/- \"+ str(max_range_from_median)\n",
        "print(\"CNN Accuracy Score on AUGMENTED Test set -> \",final_result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RgfUp_5TWED7",
        "x8zDXrk9eEy5"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}