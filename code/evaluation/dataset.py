{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJISMGGuov5gLmc7uZ4fcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/DA-ESWA/blob/main/code/evaluation/dataset.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cb9o710G00yx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "class Dataset:\n",
        "\n",
        "    def __init__(self, ds_name, language):\n",
        "        # Values for ds_name are: \"fns\", \"hss\", \"iss\"\n",
        "        # Values for language are: \"it\", \"de\", \"it_de\", \"ja\", \"tr\", \"mix\"\n",
        "        self.language = language\n",
        "        self.ds_name = ds_name\n",
        "\n",
        "        self.url_train_set = \"https://github.com/marco-siino/DA-ESWA/raw/main/data/\"+ds_name+\"/\"+ds_name+\"-train-\"+language+\".zip\"\n",
        "        self.url_test_set = \"https://github.com/marco-siino/DA-ESWA/raw/main/data/\"+ds_name+\"/\"+ds_name+\"-test-\"+language+\".zip\"\n",
        "        \n",
        "    def fetch_ds_files(self):\n",
        "        self.train_set_archive = tf.keras.utils.get_file(self.ds_name+'-train-'+self.language+'.zip', self.url_train_set,\n",
        "                                    extract=True, archive_format='zip',cache_dir='.',\n",
        "                                    cache_subdir='')    \n",
        "        self.test_set_archive  = tf.keras.utils.get_file(self.ds_name+'-test-'+self.language+'.zip', self.url_test_set,\n",
        "                                    extract=True, archive_format='zip',cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "    def organize_ds_folders(self):\n",
        "        ds_name = self.ds_name\n",
        "\n",
        "        if ds_name == 'fns':\n",
        "          self.train_folder_name = \"pan20-author-profiling-training-2020-02-23-\"+self.language\n",
        "          self.test_folder_name = \"pan20-author-profiling-test-2020-02-23-\"+self.language\n",
        "        elif ds_name == 'hss':\n",
        "          self.train_folder_name = \"pan20-author-profiling-training-2020-02-23-\"+self.language\n",
        "          self.test_folder_name = \"pan20-author-profiling-test-2020-02-23-\"+self.language\n",
        "        elif ds_name == 'iss':\n",
        "          self.train_folder_name = \"pan20-author-profiling-training-2020-02-23-\"+self.language\n",
        "          self.test_folder_name = \"pan20-author-profiling-test-2020-02-23-\"+self.language\n",
        "        else: \n",
        "          print(\"\\nNo ds_name found!\")        \n",
        "\n",
        "        os.rename(self.train_folder_name, self.ds_name+\"-train-\"+self.language)\n",
        "        os.rename(self.test_folder_name, self.ds_name+\"-test-\"+self.language) \n",
        "\n",
        "        self.source_train_dir = os.path.join(os.path.dirname(self.train_set_archive), self.ds_name+\"-train-\"+self.language)\n",
        "        self.source_test_dir = os.path.join(os.path.dirname(self.test_set_archive), self.ds_name+\"-test-\"+self.language)\n",
        "\n",
        "        ### Training Folders. ###\n",
        "        # First level directory.\n",
        "        if not os.path.exists('train_dir_'+self.ds_name+'_'+self.language):\n",
        "            os.makedirs('train_dir_'+self.ds_name+'_'+self.language)\n",
        "\n",
        "        # Class labels directory.\n",
        "        if not os.path.exists('train_dir_'+self.ds_name+'_'+self.language+'/0'):\n",
        "            os.makedirs('train_dir_'+self.ds_name+'_'+self.language+'/0')\n",
        "        if not os.path.exists('train_dir_'+self.ds_name+'_'+self.language+'/1'):\n",
        "            os.makedirs('train_dir_'+self.ds_name+'_'+self.language+'/1')\n",
        "\n",
        "        # Make Py variables.\n",
        "        self.train_dir = 'train_dir_'+self.ds_name+'_'+self.language\n",
        "\n",
        "        ## Test Folders. ##\n",
        "        # First level directory.\n",
        "        if not os.path.exists('test_dir_'+self.ds_name+'_'+self.language):\n",
        "            os.makedirs('test_dir_'+self.ds_name+'_'+self.language)\n",
        "\n",
        "        # Class labels directory.\n",
        "        if not os.path.exists('test_dir_'+self.ds_name+'_'+self.language+'/0'):\n",
        "            os.makedirs('test_dir_'+self.ds_name+'_'+self.language+'/0')\n",
        "        if not os.path.exists('test_dir_'+self.ds_name+'_'+self.language+'/1'):\n",
        "            os.makedirs('test_dir_'+self.ds_name+'_'+self.language+'/1')\n",
        "\n",
        "        # Make Py variables.\n",
        "        self.test_dir = 'test_dir_'+self.ds_name+'_'+self.language\n",
        "\n",
        "    def organize_ds_samples(self):\n",
        "\n",
        "      train_truth_file_path = self.source_train_dir+'/truth.txt'\n",
        "      test_truth_file_path = self.source_test_dir+'/truth.txt' \n",
        "\n",
        "      # Open the file truth.txt with read only permit.\n",
        "      f = open(train_truth_file_path, \"r\")\n",
        "      # use readline() to read the first line \n",
        "      line = f.readline()\n",
        "      # use the read line to read further.\n",
        "      # If the file is not empty keep reading one line\n",
        "      # at a time, till the file is empty\n",
        "      while line:\n",
        "          # Split line at :::\n",
        "          x = line.split(\":::\")\n",
        "          fNameXml = x[0]+'.xml'\n",
        "          fNameTxt = x[0]+'.txt'\n",
        "          # Second coord [0] gets just the first character (label) and not /n too.\n",
        "          label = x[1][0]\n",
        "\n",
        "          # Now move the file to the right folder.\n",
        "          if os.path.exists(self.source_train_dir+'/en/'+fNameXml):\n",
        "            os.rename(self.source_train_dir+'/en/'+fNameXml, self.train_dir+'/'+label+'/'+fNameTxt )\n",
        "\n",
        "          # use readline() to read next line\n",
        "          line = f.readline()\n",
        "\n",
        "      # Open the file truth.txt with read only permit.\n",
        "      f = open(test_truth_file_path, \"r\")\n",
        "      # use readline() to read the first line \n",
        "      line = f.readline()\n",
        "      # use the read line to read further.\n",
        "      # If the file is not empty keep reading one line\n",
        "      # at a time, till the file is empty\n",
        "      while line:\n",
        "          # Split line at :::\n",
        "          x = line.split(\":::\")\n",
        "          fNameXml = x[0]+'.xml'\n",
        "          fNameTxt = x[0]+'.txt'\n",
        "          # Second coord [0] gets just the first character (label) and not /n too.\n",
        "          label = x[1][0]\n",
        "\n",
        "          # Now move the file to the right folder.          \n",
        "          if os.path.exists(self.source_test_dir+'/en/'+fNameXml):\n",
        "            os.rename(self.source_test_dir+'/en/'+fNameXml, self.test_dir+'/'+label+'/'+fNameTxt )\n",
        "\n",
        "          # use readline() to read next line\n",
        "          line = f.readline()\n",
        "\n",
        "    def generate_keras_ds(self, batch_size):\n",
        "\n",
        "      # Generate full randomized sets.\n",
        "\n",
        "      train_set = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "          self.train_dir, \n",
        "          batch_size=batch_size,\n",
        "          shuffle=False\n",
        "          )\n",
        "\n",
        "      test_set = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "          self.test_dir, \n",
        "          batch_size=batch_size,\n",
        "          shuffle=False\n",
        "          )\n",
        "\n",
        "      self.train_set=train_set.shuffle(len(train_set),seed=1, reshuffle_each_iteration=False)\n",
        "      self.test_set=test_set.shuffle(len(test_set),seed=1, reshuffle_each_iteration=False)\n",
        "\n",
        "    def build_ds(self,batch_size):\n",
        "      self.fetch_ds_files()\n",
        "      self.organize_ds_folders()\n",
        "      self.organize_ds_samples()\n",
        "      self.generate_keras_ds(batch_size)"
      ]
    }
  ]
}